# Titanic Dataset Solution

This notebook presents a solution to the Titanic dataset challenge. It outlines the steps taken to load and prepare the data, perform exploratory data analysis (EDA), engineer features and optimise machine learning (ML) models to predict passenger survival outcomes.

# Contents

- Initialisation  
- Custom Functions  
- Data Analysis
- Preparation  
- Optimisation  
- Prediction  

# Initialisation  
In this section, the necessary libraries are imported and the Titanic dataset is loaded. The environment is set up for further analysis, and initial data checks are conducted.

# Custom Functions  
This section defines custom functions that are used throughout the notebook. These functions include data imputation, model evaluation and hyperparameter optimisation.

# Analysis  
EDA is performed to examine the distribution of key features, their relationship to survival and any potential correlations within the dataset. The presence of missing data is also assessed and the necessary steps for addressing it are outlined.

# Preparation  
Data preprocessing tasks are conducted in this section. Missing values are imputed, new features are engineered and categorical variables are encoded in preparation for the modelling phase.

# Optimisation  
This section focuses on optimising hyperparameters for multiple ML models, including Decision Trees, XGBoost, LightGBM, Random Forest, SVM and Logistic Regression. Optuna is used for hyperparameter tuning to maximise model performance.

# Prediction  
In this final section, the best models are used to make predictions on the test set.
